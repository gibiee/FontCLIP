{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow.io.gfile as gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npload(fname):\n",
    "  \"\"\"Loads `fname` and returns an np.ndarray or dict thereof.\"\"\"\n",
    "  # Load the data; use local paths directly if possible:\n",
    "  if os.path.exists(fname):\n",
    "    loaded = np.load(fname, allow_pickle=False)\n",
    "  else:\n",
    "    # For other (remote) paths go via gfile+BytesIO as np.load requires seeks.\n",
    "    with gfile.GFile(fname, \"rb\") as f:\n",
    "      data = f.read()\n",
    "    loaded = np.load(io.BytesIO(data), allow_pickle=False)\n",
    "\n",
    "  # Support loading both single-array files (np.save) and zips (np.savez).\n",
    "  if isinstance(loaded, np.ndarray):\n",
    "    return loaded\n",
    "  else:\n",
    "    return dict(loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'model_checkpoints/clippo_b16_yfcc100m_i21k_init_25c4.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = npload(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrono/accum_examples_seen ()\n",
      "chrono/accum_pause_time ()\n",
      "chrono/accum_program_time ()\n",
      "chrono/accum_train_time ()\n",
      "params/img/MAPHead_0/LayerNorm_0/bias (768,)\n",
      "params/img/MAPHead_0/LayerNorm_0/scale (768,)\n",
      "params/img/MAPHead_0/MlpBlock_0/Dense_0/bias (3072,)\n",
      "params/img/MAPHead_0/MlpBlock_0/Dense_0/kernel (768, 3072)\n",
      "params/img/MAPHead_0/MlpBlock_0/Dense_1/bias (768,)\n",
      "params/img/MAPHead_0/MlpBlock_0/Dense_1/kernel (3072, 768)\n",
      "params/img/MAPHead_0/MultiHeadDotProductAttention_0/key/bias (12, 64)\n",
      "params/img/MAPHead_0/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64)\n",
      "params/img/MAPHead_0/MultiHeadDotProductAttention_0/out/bias (768,)\n",
      "params/img/MAPHead_0/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768)\n",
      "params/img/MAPHead_0/MultiHeadDotProductAttention_0/query/bias (12, 64)\n",
      "params/img/MAPHead_0/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64)\n",
      "params/img/MAPHead_0/MultiHeadDotProductAttention_0/value/bias (12, 64)\n",
      "params/img/MAPHead_0/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64)\n",
      "params/img/MAPHead_0/probe (1, 1, 768)\n",
      "params/img/Transformer/encoder_norm/bias (768,)\n",
      "params/img/Transformer/encoder_norm/scale (768,)\n",
      "params/img/Transformer/encoderblock_0/LayerNorm_0/bias (768,)\n",
      "params/img/Transformer/encoderblock_0/LayerNorm_0/scale (768,)\n",
      "params/img/Transformer/encoderblock_0/LayerNorm_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_0/LayerNorm_1/scale (768,)\n",
      "params/img/Transformer/encoderblock_0/MlpBlock_0/Dense_0/bias (3072,)\n",
      "params/img/Transformer/encoderblock_0/MlpBlock_0/Dense_0/kernel (768, 3072)\n",
      "params/img/Transformer/encoderblock_0/MlpBlock_0/Dense_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_0/MlpBlock_0/Dense_1/kernel (3072, 768)\n",
      "params/img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/bias (768,)\n",
      "params/img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768)\n",
      "params/img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_0/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_1/LayerNorm_0/bias (768,)\n",
      "params/img/Transformer/encoderblock_1/LayerNorm_0/scale (768,)\n",
      "params/img/Transformer/encoderblock_1/LayerNorm_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_1/LayerNorm_1/scale (768,)\n",
      "params/img/Transformer/encoderblock_1/MlpBlock_0/Dense_0/bias (3072,)\n",
      "params/img/Transformer/encoderblock_1/MlpBlock_0/Dense_0/kernel (768, 3072)\n",
      "params/img/Transformer/encoderblock_1/MlpBlock_0/Dense_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_1/MlpBlock_0/Dense_1/kernel (3072, 768)\n",
      "params/img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/bias (768,)\n",
      "params/img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768)\n",
      "params/img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_1/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_10/LayerNorm_0/bias (768,)\n",
      "params/img/Transformer/encoderblock_10/LayerNorm_0/scale (768,)\n",
      "params/img/Transformer/encoderblock_10/LayerNorm_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_10/LayerNorm_1/scale (768,)\n",
      "params/img/Transformer/encoderblock_10/MlpBlock_0/Dense_0/bias (3072,)\n",
      "params/img/Transformer/encoderblock_10/MlpBlock_0/Dense_0/kernel (768, 3072)\n",
      "params/img/Transformer/encoderblock_10/MlpBlock_0/Dense_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_10/MlpBlock_0/Dense_1/kernel (3072, 768)\n",
      "params/img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/bias (768,)\n",
      "params/img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768)\n",
      "params/img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_10/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_11/LayerNorm_0/bias (768,)\n",
      "params/img/Transformer/encoderblock_11/LayerNorm_0/scale (768,)\n",
      "params/img/Transformer/encoderblock_11/LayerNorm_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_11/LayerNorm_1/scale (768,)\n",
      "params/img/Transformer/encoderblock_11/MlpBlock_0/Dense_0/bias (3072,)\n",
      "params/img/Transformer/encoderblock_11/MlpBlock_0/Dense_0/kernel (768, 3072)\n",
      "params/img/Transformer/encoderblock_11/MlpBlock_0/Dense_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_11/MlpBlock_0/Dense_1/kernel (3072, 768)\n",
      "params/img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/bias (768,)\n",
      "params/img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768)\n",
      "params/img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_11/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_2/LayerNorm_0/bias (768,)\n",
      "params/img/Transformer/encoderblock_2/LayerNorm_0/scale (768,)\n",
      "params/img/Transformer/encoderblock_2/LayerNorm_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_2/LayerNorm_1/scale (768,)\n",
      "params/img/Transformer/encoderblock_2/MlpBlock_0/Dense_0/bias (3072,)\n",
      "params/img/Transformer/encoderblock_2/MlpBlock_0/Dense_0/kernel (768, 3072)\n",
      "params/img/Transformer/encoderblock_2/MlpBlock_0/Dense_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_2/MlpBlock_0/Dense_1/kernel (3072, 768)\n",
      "params/img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/bias (768,)\n",
      "params/img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768)\n",
      "params/img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_2/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_3/LayerNorm_0/bias (768,)\n",
      "params/img/Transformer/encoderblock_3/LayerNorm_0/scale (768,)\n",
      "params/img/Transformer/encoderblock_3/LayerNorm_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_3/LayerNorm_1/scale (768,)\n",
      "params/img/Transformer/encoderblock_3/MlpBlock_0/Dense_0/bias (3072,)\n",
      "params/img/Transformer/encoderblock_3/MlpBlock_0/Dense_0/kernel (768, 3072)\n",
      "params/img/Transformer/encoderblock_3/MlpBlock_0/Dense_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_3/MlpBlock_0/Dense_1/kernel (3072, 768)\n",
      "params/img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/bias (768,)\n",
      "params/img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768)\n",
      "params/img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_3/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_4/LayerNorm_0/bias (768,)\n",
      "params/img/Transformer/encoderblock_4/LayerNorm_0/scale (768,)\n",
      "params/img/Transformer/encoderblock_4/LayerNorm_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_4/LayerNorm_1/scale (768,)\n",
      "params/img/Transformer/encoderblock_4/MlpBlock_0/Dense_0/bias (3072,)\n",
      "params/img/Transformer/encoderblock_4/MlpBlock_0/Dense_0/kernel (768, 3072)\n",
      "params/img/Transformer/encoderblock_4/MlpBlock_0/Dense_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_4/MlpBlock_0/Dense_1/kernel (3072, 768)\n",
      "params/img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/bias (768,)\n",
      "params/img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768)\n",
      "params/img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_4/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_5/LayerNorm_0/bias (768,)\n",
      "params/img/Transformer/encoderblock_5/LayerNorm_0/scale (768,)\n",
      "params/img/Transformer/encoderblock_5/LayerNorm_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_5/LayerNorm_1/scale (768,)\n",
      "params/img/Transformer/encoderblock_5/MlpBlock_0/Dense_0/bias (3072,)\n",
      "params/img/Transformer/encoderblock_5/MlpBlock_0/Dense_0/kernel (768, 3072)\n",
      "params/img/Transformer/encoderblock_5/MlpBlock_0/Dense_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_5/MlpBlock_0/Dense_1/kernel (3072, 768)\n",
      "params/img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/bias (768,)\n",
      "params/img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768)\n",
      "params/img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_5/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_6/LayerNorm_0/bias (768,)\n",
      "params/img/Transformer/encoderblock_6/LayerNorm_0/scale (768,)\n",
      "params/img/Transformer/encoderblock_6/LayerNorm_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_6/LayerNorm_1/scale (768,)\n",
      "params/img/Transformer/encoderblock_6/MlpBlock_0/Dense_0/bias (3072,)\n",
      "params/img/Transformer/encoderblock_6/MlpBlock_0/Dense_0/kernel (768, 3072)\n",
      "params/img/Transformer/encoderblock_6/MlpBlock_0/Dense_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_6/MlpBlock_0/Dense_1/kernel (3072, 768)\n",
      "params/img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/bias (768,)\n",
      "params/img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768)\n",
      "params/img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_6/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_7/LayerNorm_0/bias (768,)\n",
      "params/img/Transformer/encoderblock_7/LayerNorm_0/scale (768,)\n",
      "params/img/Transformer/encoderblock_7/LayerNorm_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_7/LayerNorm_1/scale (768,)\n",
      "params/img/Transformer/encoderblock_7/MlpBlock_0/Dense_0/bias (3072,)\n",
      "params/img/Transformer/encoderblock_7/MlpBlock_0/Dense_0/kernel (768, 3072)\n",
      "params/img/Transformer/encoderblock_7/MlpBlock_0/Dense_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_7/MlpBlock_0/Dense_1/kernel (3072, 768)\n",
      "params/img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/bias (768,)\n",
      "params/img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768)\n",
      "params/img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_7/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_8/LayerNorm_0/bias (768,)\n",
      "params/img/Transformer/encoderblock_8/LayerNorm_0/scale (768,)\n",
      "params/img/Transformer/encoderblock_8/LayerNorm_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_8/LayerNorm_1/scale (768,)\n",
      "params/img/Transformer/encoderblock_8/MlpBlock_0/Dense_0/bias (3072,)\n",
      "params/img/Transformer/encoderblock_8/MlpBlock_0/Dense_0/kernel (768, 3072)\n",
      "params/img/Transformer/encoderblock_8/MlpBlock_0/Dense_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_8/MlpBlock_0/Dense_1/kernel (3072, 768)\n",
      "params/img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/bias (768,)\n",
      "params/img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768)\n",
      "params/img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_8/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_9/LayerNorm_0/bias (768,)\n",
      "params/img/Transformer/encoderblock_9/LayerNorm_0/scale (768,)\n",
      "params/img/Transformer/encoderblock_9/LayerNorm_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_9/LayerNorm_1/scale (768,)\n",
      "params/img/Transformer/encoderblock_9/MlpBlock_0/Dense_0/bias (3072,)\n",
      "params/img/Transformer/encoderblock_9/MlpBlock_0/Dense_0/kernel (768, 3072)\n",
      "params/img/Transformer/encoderblock_9/MlpBlock_0/Dense_1/bias (768,)\n",
      "params/img/Transformer/encoderblock_9/MlpBlock_0/Dense_1/kernel (3072, 768)\n",
      "params/img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/bias (768,)\n",
      "params/img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768)\n",
      "params/img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64)\n",
      "params/img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/bias (12, 64)\n",
      "params/img/Transformer/encoderblock_9/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64)\n",
      "params/img/embedding/bias (768,)\n",
      "params/img/embedding/kernel (16, 16, 3, 768)\n",
      "params/img/head/bias (768,)\n",
      "params/img/head/kernel (768, 768)\n",
      "params/img/pos_embedding (1, 196, 768)\n",
      "params/t (1,)\n"
     ]
    }
   ],
   "source": [
    "for key in params.keys():\n",
    "  if 'opt' not in key:\n",
    "    print(key, params[key].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params/img/MAPHead_0/LayerNorm_0/bias (768,)\n",
      "params/img/MAPHead_0/LayerNorm_0/scale (768,)\n",
      "params/img/MAPHead_0/MlpBlock_0/Dense_0/bias (3072,)\n",
      "params/img/MAPHead_0/MlpBlock_0/Dense_0/kernel (768, 3072)\n",
      "params/img/MAPHead_0/MlpBlock_0/Dense_1/bias (768,)\n",
      "params/img/MAPHead_0/MlpBlock_0/Dense_1/kernel (3072, 768)\n",
      "params/img/MAPHead_0/MultiHeadDotProductAttention_0/key/bias (12, 64)\n",
      "params/img/MAPHead_0/MultiHeadDotProductAttention_0/key/kernel (768, 12, 64)\n",
      "params/img/MAPHead_0/MultiHeadDotProductAttention_0/out/bias (768,)\n",
      "params/img/MAPHead_0/MultiHeadDotProductAttention_0/out/kernel (12, 64, 768)\n",
      "params/img/MAPHead_0/MultiHeadDotProductAttention_0/query/bias (12, 64)\n",
      "params/img/MAPHead_0/MultiHeadDotProductAttention_0/query/kernel (768, 12, 64)\n",
      "params/img/MAPHead_0/MultiHeadDotProductAttention_0/value/bias (12, 64)\n",
      "params/img/MAPHead_0/MultiHeadDotProductAttention_0/value/kernel (768, 12, 64)\n",
      "params/img/MAPHead_0/probe (1, 1, 768)\n"
     ]
    }
   ],
   "source": [
    "for key in params.keys():\n",
    "  if 'params/img/MAPHead_0' in key:\n",
    "    print(key, params[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgfont-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
